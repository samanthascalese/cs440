{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8304456b",
   "metadata": {},
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f886fae",
   "metadata": {},
   "source": [
    "### Step B\n",
    "Step B: The next objective is to scale up the size of filtering problems like the above one that you can solve. For this question, you will use large maps (e.g., 100 by 50), where you randomly assign terrain types to each cell out of the four possible types (50% normal cells, 20% highway cells, 20% hard to traverse and 10% blocked cells).\n",
    "\n",
    "First, generate “ground truth” data, i.e., generate sequences of actions and sensor readings to test your algorithm. For this purpose, first randomly select a non-blocked cell as the initial location of your agent in the world $x_{0}$. Then, randomly generate a sequence of 100 actions, i.e., randomly select actions from the set α = {Up, Left, Down, Right} and generate a string of length 100. For each action starting from the initial location $x_{0}$ apply:\n",
    "- the **transition model** (i.e., 90% follow the action - when you collide stay in place, 10% stay in place), in order to get the next ground truth state $x_{i+1}$\n",
    "- the **observation model** (i.e., 90% the correct terrain type and 5% one of the other two types), in order to get the “ground truth” sensor reading $e_{i+1}$\n",
    "\n",
    "Once you have generated the 100 actions, the 100 ground truth states and the 100 observations, store them in a file. Generate 10 such files per map and for 10 different maps of the world (i.e., 100 total ground truth files), as different experiments inside the large maps. The format for the file can be as follows:\n",
    "- $x_{0}y_{0}$: coordinates of initial point\n",
    "- $x_{i}y_{i}$: 100 coordinates of the consecutive points that the agent actually goes through separated by a new line\n",
    "- $α_{i}$: 100 characters indicating the type of action executed {U, L, D, R} separated by a new line\n",
    "- $e_{i}$: 100 characters indicating the sensor reading {N, H, T} collected by the agent as it moves\n",
    "\n",
    "In your report, provide examples of ground truth paths and the corresponding action and\n",
    "sensor readings generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4da24fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716dc185",
   "metadata": {},
   "source": [
    "#### (1) Produce ten 100 x 50 grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6022df02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_grid(rows, cols):\n",
    "    grid = [['']*cols for i in range(rows)]\n",
    "    \n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            \n",
    "            prob = random.random()\n",
    "            if (prob <= 0.5):\n",
    "                grid[r][c] = 'N' # 50% normal\n",
    "            elif (prob <= 0.7):\n",
    "                grid[r][c] = 'H' # 20% highway\n",
    "            elif (prob <= 0.9):\n",
    "                grid[r][c] = 'T' # 20% hard-to-traverse\n",
    "            else:\n",
    "                grid[r][c] = 'B' # 10% blocked\n",
    "                \n",
    "    return grid\n",
    "\n",
    "\n",
    "def save_grid_as_csv(grid, fname):\n",
    "    np.savetxt(fname, grid, delimiter = ',', fmt='%s')\n",
    "    \n",
    "\n",
    "# produce 10 grids\n",
    "rows = 50\n",
    "cols = 100\n",
    "grids = []\n",
    "for i in range(10):\n",
    "    grids.append(create_grid(rows, cols))\n",
    "    save_grid_as_csv(grids[i], f'grid{i+1}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7bc32c",
   "metadata": {},
   "source": [
    "#### (2) Produce ten 'ground truth' data per grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4b60b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ground_truth(grid, fname, n):\n",
    "    f = open(fname, 'w')\n",
    "    rows, cols = len(grid), len(grid[0])\n",
    "    \n",
    "    # ensure valid, non-blocked starting point\n",
    "    x = [random.randrange(0, rows), random.randrange(0, cols)]\n",
    "    while (grid[x[0]][x[1]] == 'B'):\n",
    "        x = [random.randrange(0, rows), random.randrange(0, cols)]\n",
    "    \n",
    "    f.write(f'{x[0]},{x[1]}\\n') # write true path\n",
    "    \n",
    "    actions, sensor = ['']*n, ['']*n\n",
    "    for i in range(n):\n",
    "        actions[i] = random.choice(['U', 'L', 'D', 'R'])\n",
    "        \n",
    "        prob = random.random()\n",
    "        if (prob <= 0.9): # 90% action succeeds, unless colliding into blocked cell or edge\n",
    "            if (actions[i] == 'U'):\n",
    "                if (x[0]-1 >= 0 and grid[x[0]-1][x[1]] != 'B'):\n",
    "                    x[0] -= 1\n",
    "            \n",
    "            if (actions[i] == 'L'):\n",
    "                if (x[1]-1 >= 0 and grid[x[0]][x[1]-1] != 'B'):\n",
    "                    x[1] -= 1\n",
    "            \n",
    "            if (actions[i] == 'D'):\n",
    "                if (x[0]+1 < rows and grid[x[0]+1][x[1]] != 'B'):\n",
    "                    x[0] += 1\n",
    "            \n",
    "            if (actions[i] == 'R'):\n",
    "                if (x[1]+1 < cols and grid[x[0]][x[1]+1] != 'B'):\n",
    "                    x[1] += 1\n",
    "            \n",
    "        f.write(f'{x[0]},{x[1]}\\n') # or, 10% action fails, stays in place\n",
    "            \n",
    "        \n",
    "        prob = random.random()\n",
    "        if (prob <= 0.9): # 90% sensor reads terrain correctly\n",
    "            sensor[i] = grid[x[0]][x[1]]\n",
    "        \n",
    "        else: # or, 5% sensor incorrectly reads either of the other two types\n",
    "            terrains = ['N', 'H', 'T']\n",
    "            terrains.remove(grid[x[0]][x[1]])\n",
    "            sensor[i] = random.choice(terrains)\n",
    "            \n",
    "    \n",
    "    # write actions and observations to 'ground truth' data\n",
    "    for i in range(n):\n",
    "        f.write(f'{actions[i]}\\n')\n",
    "    for i in range(n):\n",
    "        f.write(f'{sensor[i]}\\n')\n",
    "        \n",
    "    f.close\n",
    "    return\n",
    "\n",
    "\n",
    "# produce 10 'ground truth' data per grid\n",
    "n = 100\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        create_ground_truth(grids[i], f'grid{i+1}_groundtruth{j+1}.txt', n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d750de",
   "metadata": {},
   "source": [
    "### Step C\n",
    "Step C: Demonstrate the capability of estimating the position of the agent inside the world given only the actions and observations indicated in these files. In particular, your program should be able to load a “ground truth” file and a map. Then, after each action/sensor reading pair, it should be able to compute the probability that the agent is in each cell of the map by applying the filtering algorithm. Visualize the different probabilities on your map (e.g., think of a heatmap) or provide a capability to indicate the probability on any cell of the map. Visualize the ground truth location of the agent inside the world at the corresponding step. Your visualization should be updated with each new action/sensor reading pair until you consume all 100 readings.\n",
    "\n",
    "Attach example heat maps in your report after 10, 50 and 100 iterations. Indicate the ground truth path up to this point in each case.\n",
    "\n",
    "For each of the 100 experiments, compute the error (as distance inside the grid world) between the true location of the agent and the maximum likelihood estimation (i.e., the cell with the highest probability according to the filtering algorithm) as the number of readings increases. For the computation of the maximum likelihood estimation, ties can be broken randomly. Generate a plot of the average error over all 100 experiments as the number of readings increases. For this plot, you can ignore the first 5 iterations as many cells will have the same probability in the beginning.\n",
    "\n",
    "For each of the 100 experiments, keep track of the probability that the cell where the agent is actually located (which changes over time) is assigned by the filtering algorithm. Generate a plot of the average probability of the ground truth cell over 100 experiments as the number of readings increases. Here you can start with the uniform probability assigned to the cell in the beginning of this process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7ccbcd",
   "metadata": {},
   "source": [
    "#### (3) Read information from 'ground truth' files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e88521d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(fname, n):\n",
    "    f = open(fname)\n",
    "    \n",
    "    true_path = [] # true path traversed\n",
    "    actions = []   # attempted actions\n",
    "    sensor = []    # sensor readings\n",
    "    \n",
    "    for i in range(n+1):\n",
    "        l = f.readline()\n",
    "        x = l.split(',')\n",
    "        true_path.append([int(x[0]), int(x[1])])\n",
    "        \n",
    "    for i in range(n):\n",
    "        l = f.readline()\n",
    "        actions.append(l[0])\n",
    "        \n",
    "    for i in range(n):\n",
    "        l = f.readline()\n",
    "        sensor.append(l[0])\n",
    "    \n",
    "    f.close()\n",
    "    return [true_path, actions, sensor]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8097bab7",
   "metadata": {},
   "source": [
    "#### (4) Apply filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9141ca5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtering(grid, itr, prob_matrix, true_path, actions, sensor):\n",
    "    rows, cols = len(grid), len(grid[0])\n",
    "    err, true_prob = [0]*itr, [0]*itr\n",
    "\n",
    "    for i in range(itr):\n",
    "        alpha, sigma = 1, 0 # for normalization\n",
    "        max_prob, max_x = 0, [] # for calculating error\n",
    "        \n",
    "        prior = np.copy(prob_matrix)\n",
    "        \n",
    "        for r in range(rows):\n",
    "            for c in range(cols):\n",
    "                \n",
    "                # transition model\n",
    "                if (actions[i] == 'U'):\n",
    "                    if (r == rows-1):\n",
    "                        sigma = prior[r][c]*0.1 \n",
    "                    else:\n",
    "                        sigma = prior[r][c]*0.1 + prior[r+1][c]*0.9                        \n",
    "                \n",
    "                elif (actions[i] == 'L'):\n",
    "                    if (c == cols-1):\n",
    "                        sigma = prior[r][c]*0.1\n",
    "                    else:\n",
    "                        sigma = prior[r][c]*0.1 + prior[r][c+1]*0.9  \n",
    "                \n",
    "                elif (actions[i] == 'D'):\n",
    "                    if (r == 0):\n",
    "                        sigma = prior[r][c]*0.1\n",
    "                    else:\n",
    "                        sigma = prior[r][c]*0.1 + prior[r-1][c]*0.9                      \n",
    "                \n",
    "                elif (actions[i] == 'R'):\n",
    "                    if (c == 0):\n",
    "                        sigma = prior[r][c]*0.1\n",
    "                    else:\n",
    "                        sigma = prior[r][c]*0.1 + prior[r][c-1]*0.9\n",
    "                \n",
    "                \n",
    "                # observational model\n",
    "                if (sensor[i] == grid[r][c]):\n",
    "                    prob_matrix[r][c] = sigma * 0.9\n",
    "                else:\n",
    "                    prob_matrix[r][c] = sigma * 0.05\n",
    "                \n",
    "                if (grid[r][c] == 'B'):\n",
    "                    prob_matrix[r][c] = 0\n",
    "                \n",
    "                \n",
    "                # for calculating error\n",
    "                if (max_prob < prob_matrix[r][c]):\n",
    "                    max_prob = prob_matrix[r][c]\n",
    "                    max_x = [r,c]\n",
    "                    \n",
    "                # for normalization\n",
    "                sigma += prob_matrix[r][c]\n",
    "            \n",
    "        # normalize\n",
    "        if (sigma != 0):\n",
    "            alpha = 1/sigma\n",
    "        prob_matrix = np.multiply(prob_matrix, alpha)\n",
    "        \n",
    "        # calculate error\n",
    "        err[i] = math.sqrt((max_x[0] - true_path[i][0])**2 + (max_x[1] - true_path[i][1])**2)\n",
    "        true_prob[i] = prob_matrix[true_path[i][0]][true_path[i][1]]\n",
    "        \n",
    "    return [prob_matrix, true_prob, err]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a090b2",
   "metadata": {},
   "source": [
    "#### (5) Produce example heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3223fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns # for pandas headmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab50fe44",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib tk\n",
    "\n",
    "def plot_heatmap(grid, fname, itr):\n",
    "    rows, cols = len(grid), len(grid[0])\n",
    "    \n",
    "    info = read_file(fname, 100)\n",
    "    true_path, actions, sensor = info\n",
    "    \n",
    "    # set up inital belief\n",
    "    prior = (rows*cols)*0.9/(rows*cols)\n",
    "    prob_matrix = np.array([[prior]*cols]*rows)\n",
    "    \n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            if (grid[r][c] == 'B'):\n",
    "                prob_matrix[r][c] = 0\n",
    "    \n",
    "    \n",
    "    # apply filtering\n",
    "    ans = filtering(grid, itr, prob_matrix, true_path, actions, sensor)\n",
    "    prob_matrix = np.copy(ans[0])\n",
    "    \n",
    "    \n",
    "    # set up log w/ accurate minimum values for blocked cells\n",
    "    log = np.copy(prob_matrix)\n",
    "    log = np.log10(log, where=(log!=0))\n",
    "    m = np.min(log)\n",
    "    \n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            if (grid[r][c] == 'B'):\n",
    "                log[r][c] = m-1\n",
    "    \n",
    "    \n",
    "    # plot heatmap\n",
    "    plt.title(f'Heatmap for {fname} - {itr} iterations')\n",
    "    ax = sns.heatmap(log, linewidth = 0.5, cmap = \"coolwarm\", cbar = False)\n",
    "\n",
    "\n",
    "    # draw true path of agent\n",
    "    for i in range(itr-1):\n",
    "        y = [true_path[i][0], true_path[i+1][0]]\n",
    "        x = [true_path[i][1], true_path[i+1][1]]\n",
    "        plt.plot(x, y, color=\"BLACK\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4a9b3da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(grids[6], 'grid7_groundtruth1.txt', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b462f5b",
   "metadata": {},
   "source": [
    "#### (6) Calculate average error and probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c04c4a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[56.4243463  51.3656025  44.35878765 40.00712197 39.03155913 36.6238886\n",
      " 37.02321025 36.02233186 31.5627002  31.56098397 35.03879409 34.00330228\n",
      " 33.33011175 35.22933838 32.98786467 33.46383734 31.92305923 31.63751059\n",
      " 31.74835211 32.66389315 32.52383548 29.90093482 30.62203618 30.57454347\n",
      " 31.02760567 28.15110391 27.82870627 28.33439654 28.20457006 25.70322218\n",
      " 25.31309066 27.68485009 29.12145373 26.73902366 26.13613242 27.73211528\n",
      " 25.74673182 27.68138201 27.69376122 24.77761535 26.19302822 26.58878977\n",
      " 24.16488895 25.3594705  24.07540251 21.34574717 21.00692528 22.90434381\n",
      " 23.96650897 23.28406427 24.09386315 22.44918261 22.41706794 22.69844613\n",
      " 21.75160394 23.39438612 22.12503823 19.28600707 20.33298576 20.52899804\n",
      " 17.93622501 17.22706531 19.15217902 19.7988612  19.10030117 17.60198757\n",
      " 18.82386836 18.88608024 18.5471338  18.17909559 18.14887541 17.83392823\n",
      " 16.66833693 17.35911413 18.37065036 17.21618434 18.12141616 17.90232026\n",
      " 17.42277315 17.37865283 16.87136366 16.39645005 16.04490287 15.46141063\n",
      " 16.19969635 16.75022493 16.15342654 16.12466772 15.1929904  17.85125186\n",
      " 17.3729622  16.21750511 15.87046033 14.73075208 12.70222519 13.91669772\n",
      " 13.63160244 13.91781737 14.00644791 14.00641158] [1.92712753e+00 9.45399621e+01 1.09220944e+03 9.44324740e+04\n",
      " 1.33860881e+06 7.59054649e+07 2.13925807e+11 1.94705558e+11\n",
      " 3.15068431e+14 6.36844994e+15 5.99261175e+16 3.07653550e+17\n",
      " 4.90256918e+18 1.08222952e+19 1.61870967e+17 1.32852093e+19\n",
      " 3.58121739e+21 3.93635487e+21 3.15522975e+22 8.03081370e+25\n",
      " 5.07278867e+22 8.24928041e+24 3.57904847e+22 6.36600336e+23\n",
      " 1.53986051e+27 6.00694271e+27 3.28818694e+29 3.28579124e+30\n",
      " 2.97196755e+32 4.56925331e+25 3.15428628e+27 4.18083290e+28\n",
      " 8.82219683e+29 4.44221578e+32 8.12586723e+33 4.92645496e+35\n",
      " 5.71490123e+37 3.16107585e+37 4.56752494e+39 8.22154537e+40\n",
      " 4.22866360e+43 2.03911809e+34 5.96337284e+37 4.96599654e+33\n",
      " 1.57739176e+35 1.61022998e+34 3.47751703e+33 6.77839057e+32\n",
      " 1.60343498e+34 1.34988042e+35 7.99633469e+35 4.60098598e+36\n",
      " 7.16218292e+30 3.49444175e+31 2.51635023e+32 5.97512616e+33\n",
      " 8.46431280e+34 1.71236514e+38 3.03503423e+39 2.33339179e+35\n",
      " 1.24494779e+36 1.66661270e+37 8.23810036e+37 1.47262694e+39\n",
      " 8.04845375e+38 4.38288708e+42 1.06440264e+43 3.71150172e+39\n",
      " 1.45607413e+42 1.74298605e+44 2.65492670e+46 4.83030610e+44\n",
      " 1.31539653e+45 1.76670813e+47 7.69372492e+45 1.06721555e+43\n",
      " 4.48908882e+40 2.13332014e+41 8.51619218e+43 6.09848319e+42\n",
      " 1.71587065e+44 8.75184948e+45 2.03938050e+47 1.90615847e+48\n",
      " 1.17466274e+48 6.74317858e+47 4.03950591e+46 7.61881055e+44\n",
      " 4.04761457e+46 7.08996119e+43 6.73431643e+43 6.59922378e+42\n",
      " 2.84015071e+42 4.23896777e+44 8.54388196e+47 1.77429747e+45\n",
      " 1.71558137e+46 1.55739013e+46 4.77585077e+49 8.62395003e+50]\n"
     ]
    }
   ],
   "source": [
    "itr = 100\n",
    "avg_error, avg_prob = [0]*itr, [0]*itr\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    grid = grids[i]\n",
    "    rows, cols = len(grid), len(grid[0])\n",
    "    \n",
    "    for j in range(10):\n",
    "        info = read_file(f'grid{i+1}_groundtruth{j+1}.txt', 100)\n",
    "        true_path, actions, sensor = info\n",
    "\n",
    "        # set up inital belief\n",
    "        prior = (rows*cols)*0.9/(rows*cols)\n",
    "        prob_matrix = np.array([[prior]*cols]*rows)\n",
    "        for r in range(rows):\n",
    "            for c in range(cols):\n",
    "                if (grid[r][c] == 'B'):\n",
    "                    prob_matrix[r][c] = 0\n",
    "        \n",
    "        # apply filtering\n",
    "        ans = filtering(grid, itr, prob_matrix, true_path, actions, sensor)\n",
    "        avg_error = np.add(avg_error, ans[2])\n",
    "        avg_prob = np.add(avg_prob, ans[1])\n",
    "        \n",
    "\n",
    "# calculate average errors and probabilities\n",
    "avg_error = np.multiply(avg_error, 1/itr)\n",
    "avg_prob = np.multiply(avg_prob, 1/itr)\n",
    "\n",
    "print(avg_error, avg_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c9ee34d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(2)\n",
    "plt.plot(avg_error[5:])\n",
    "plt.title(\"The Average Distance between the True Path and Prediction\")\n",
    "plt.ylabel(\"Distance\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.show()\n",
    "plt.figure(3)\n",
    "plt.plot(avg_prob)\n",
    "plt.title(\"The Average Probability of the True Path\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
